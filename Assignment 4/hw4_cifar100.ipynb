{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "356c8409",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-12T03:30:40.609605Z",
          "iopub.status.busy": "2022-11-12T03:30:40.609149Z",
          "iopub.status.idle": "2022-11-12T05:27:50.273994Z",
          "shell.execute_reply": "2022-11-12T05:27:50.272676Z"
        },
        "papermill": {
          "duration": 7029.671242,
          "end_time": "2022-11-12T05:27:50.276222",
          "exception": false,
          "start_time": "2022-11-12T03:30:40.604980",
          "status": "completed"
        },
        "tags": [],
        "id": "356c8409",
        "outputId": "099aa96c-8505-4d9b-c3f6-0e500c8a6abd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"googlenet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 96)   2688        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 96)   384         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 96)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   3104        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 32)   27680       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   76832       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 96)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   3104        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 128)  0           activation_1[0][0]               \n",
            "                                                                 activation_2[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 32)   4128        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 48)   55344       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 48)   153648      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 32)   4128        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 160)  0           activation_4[0][0]               \n",
            "                                                                 activation_5[0][0]               \n",
            "                                                                 activation_6[0][0]               \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 15, 15, 80)   115280      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 15, 15, 80)   320         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 15, 15, 80)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 160)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 15, 15, 240)  0           activation_7[0][0]               \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 15, 15, 112)  26992       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 15, 15, 48)   103728      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 15, 15, 32)   192032      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 15, 15, 112)  448         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 15, 15, 48)   192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 15, 15, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 15, 15, 240)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 15, 15, 112)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 15, 15, 48)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 15, 15, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 15, 15, 48)   11568       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 15, 15, 240)  0           activation_8[0][0]               \n",
            "                                                                 activation_9[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 15, 15, 96)   23136       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 15, 15, 64)   138304      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 15, 15, 32)   192032      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 15, 15, 96)   384         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 15, 15, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 15, 15, 32)   128         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 15, 15, 240)  0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 15, 15, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 15, 15, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 15, 15, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 15, 15, 32)   7712        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 15, 15, 224)  0           activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 15, 15, 80)   18000       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 15, 15, 80)   161360      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 15, 15, 32)   179232      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 15, 15, 80)   320         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 15, 15, 80)   320         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 15, 15, 32)   128         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 15, 15, 224)  0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 15, 15, 80)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 15, 15, 80)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 15, 15, 32)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 15, 15, 32)   7200        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 15, 15, 224)  0           activation_14[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 15, 15, 48)   10800       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 15, 15, 96)   193632      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 15, 15, 32)   179232      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 15, 15, 48)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 15, 15, 96)   384         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 15, 15, 32)   128         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 15, 15, 224)  0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 15, 15, 48)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 15, 15, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 15, 15, 32)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 15, 15, 32)   7200        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 15, 15, 208)  0           activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 15, 15, 112)  23408       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 15, 15, 48)   89904       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 15, 15, 32)   166432      concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 15, 15, 112)  448         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 15, 15, 48)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 15, 15, 32)   128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 15, 15, 208)  0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 15, 15, 112)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 15, 15, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 15, 15, 32)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 15, 15, 48)   10032       max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 15, 15, 240)  0           activation_20[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 96)     207456      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 7, 7, 96)     384         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 7, 7, 96)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 7, 7, 240)    0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 7, 7, 336)    0           activation_23[0][0]              \n",
            "                                                                 max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 176)    59312       concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 160)    484000      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 96)     806496      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 7, 7, 176)    704         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 7, 7, 160)    640         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 96)     384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 7, 7, 336)    0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 7, 7, 176)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 7, 7, 160)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 96)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 96)     32352       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 7, 7, 528)    0           activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 176)    93104       concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 160)    760480      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 96)     1267296     concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 7, 7, 176)    704         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 7, 7, 160)    640         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 528)    0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 7, 7, 176)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 7, 7, 160)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 96)     50784       max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 7, 7, 528)    0           activation_27[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 528)    0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1, 1, 528)    0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 528)          0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          52900       flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 100)          0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 6,011,268\n",
            "Trainable params: 6,006,660\n",
            "Non-trainable params: 4,608\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-12 03:30:55.870129: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2022-11-12 03:31:00.596293: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 95s 129ms/step - loss: 3.8317 - top_k_categorical_accuracy: 0.3268 - val_loss: 3.8906 - val_top_k_categorical_accuracy: 0.3709\n",
            "Epoch 2/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 3.0360 - top_k_categorical_accuracy: 0.5465 - val_loss: 3.5400 - val_top_k_categorical_accuracy: 0.4915\n",
            "Epoch 3/75\n",
            "625/625 [==============================] - 87s 138ms/step - loss: 2.6064 - top_k_categorical_accuracy: 0.6515 - val_loss: 3.1443 - val_top_k_categorical_accuracy: 0.5555\n",
            "Epoch 4/75\n",
            "625/625 [==============================] - 87s 138ms/step - loss: 2.3179 - top_k_categorical_accuracy: 0.7185 - val_loss: 2.5473 - val_top_k_categorical_accuracy: 0.6663\n",
            "Epoch 5/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 2.1127 - top_k_categorical_accuracy: 0.7596 - val_loss: 3.1642 - val_top_k_categorical_accuracy: 0.6259\n",
            "Epoch 6/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 1.9574 - top_k_categorical_accuracy: 0.7882 - val_loss: 2.2081 - val_top_k_categorical_accuracy: 0.7410\n",
            "Epoch 7/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 1.8255 - top_k_categorical_accuracy: 0.8134 - val_loss: 2.7122 - val_top_k_categorical_accuracy: 0.6621\n",
            "Epoch 8/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 1.7147 - top_k_categorical_accuracy: 0.8300 - val_loss: 1.8500 - val_top_k_categorical_accuracy: 0.8048\n",
            "Epoch 9/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 1.6068 - top_k_categorical_accuracy: 0.8502 - val_loss: 2.0823 - val_top_k_categorical_accuracy: 0.7733\n",
            "Epoch 10/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 1.5323 - top_k_categorical_accuracy: 0.8605 - val_loss: 1.9909 - val_top_k_categorical_accuracy: 0.7840\n",
            "Epoch 11/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 1.4459 - top_k_categorical_accuracy: 0.8727 - val_loss: 1.9447 - val_top_k_categorical_accuracy: 0.7954\n",
            "Epoch 12/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 1.3869 - top_k_categorical_accuracy: 0.8832 - val_loss: 2.5191 - val_top_k_categorical_accuracy: 0.7313\n",
            "Epoch 13/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 1.3183 - top_k_categorical_accuracy: 0.8917 - val_loss: 1.9987 - val_top_k_categorical_accuracy: 0.7900\n",
            "Epoch 14/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 1.2590 - top_k_categorical_accuracy: 0.9017 - val_loss: 1.5636 - val_top_k_categorical_accuracy: 0.8582\n",
            "Epoch 15/75\n",
            "625/625 [==============================] - 86s 138ms/step - loss: 1.2062 - top_k_categorical_accuracy: 0.9069 - val_loss: 2.1936 - val_top_k_categorical_accuracy: 0.7759\n",
            "Epoch 16/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 1.1486 - top_k_categorical_accuracy: 0.9154 - val_loss: 1.9360 - val_top_k_categorical_accuracy: 0.8178\n",
            "Epoch 17/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 1.1019 - top_k_categorical_accuracy: 0.9202 - val_loss: 2.1975 - val_top_k_categorical_accuracy: 0.7789\n",
            "Epoch 18/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 1.0538 - top_k_categorical_accuracy: 0.9269 - val_loss: 1.5189 - val_top_k_categorical_accuracy: 0.8657\n",
            "Epoch 19/75\n",
            "625/625 [==============================] - 86s 138ms/step - loss: 0.9987 - top_k_categorical_accuracy: 0.9333 - val_loss: 1.6806 - val_top_k_categorical_accuracy: 0.8549\n",
            "Epoch 20/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.9481 - top_k_categorical_accuracy: 0.9396 - val_loss: 1.6631 - val_top_k_categorical_accuracy: 0.8542\n",
            "Epoch 21/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.9143 - top_k_categorical_accuracy: 0.9423 - val_loss: 1.6820 - val_top_k_categorical_accuracy: 0.8514\n",
            "Epoch 22/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.8780 - top_k_categorical_accuracy: 0.9491 - val_loss: 1.5311 - val_top_k_categorical_accuracy: 0.8635\n",
            "Epoch 23/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.8421 - top_k_categorical_accuracy: 0.9517 - val_loss: 1.4452 - val_top_k_categorical_accuracy: 0.8877\n",
            "Epoch 24/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.7951 - top_k_categorical_accuracy: 0.9575 - val_loss: 1.6539 - val_top_k_categorical_accuracy: 0.8536\n",
            "Epoch 25/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.7622 - top_k_categorical_accuracy: 0.9591 - val_loss: 1.8754 - val_top_k_categorical_accuracy: 0.8420\n",
            "Epoch 26/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.7268 - top_k_categorical_accuracy: 0.9628 - val_loss: 1.4692 - val_top_k_categorical_accuracy: 0.8865\n",
            "Epoch 27/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.7023 - top_k_categorical_accuracy: 0.9644 - val_loss: 1.5454 - val_top_k_categorical_accuracy: 0.8750\n",
            "Epoch 28/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.6664 - top_k_categorical_accuracy: 0.9675 - val_loss: 1.4749 - val_top_k_categorical_accuracy: 0.8765\n",
            "Epoch 29/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.6406 - top_k_categorical_accuracy: 0.9714 - val_loss: 1.5271 - val_top_k_categorical_accuracy: 0.8808\n",
            "Epoch 30/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.6029 - top_k_categorical_accuracy: 0.9742 - val_loss: 1.6789 - val_top_k_categorical_accuracy: 0.8612\n",
            "Epoch 31/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.5843 - top_k_categorical_accuracy: 0.9762 - val_loss: 1.4753 - val_top_k_categorical_accuracy: 0.8918\n",
            "Epoch 32/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.5617 - top_k_categorical_accuracy: 0.9776 - val_loss: 1.7348 - val_top_k_categorical_accuracy: 0.8720\n",
            "Epoch 33/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.5284 - top_k_categorical_accuracy: 0.9802 - val_loss: 1.7578 - val_top_k_categorical_accuracy: 0.8604\n",
            "Epoch 34/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.5035 - top_k_categorical_accuracy: 0.9821 - val_loss: 1.6085 - val_top_k_categorical_accuracy: 0.8792\n",
            "Epoch 35/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.4809 - top_k_categorical_accuracy: 0.9834 - val_loss: 1.6650 - val_top_k_categorical_accuracy: 0.8707\n",
            "Epoch 36/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.4586 - top_k_categorical_accuracy: 0.9859 - val_loss: 1.7002 - val_top_k_categorical_accuracy: 0.8822\n",
            "Epoch 37/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.4392 - top_k_categorical_accuracy: 0.9861 - val_loss: 1.7569 - val_top_k_categorical_accuracy: 0.8738\n",
            "Epoch 38/75\n",
            "625/625 [==============================] - 86s 138ms/step - loss: 0.4146 - top_k_categorical_accuracy: 0.9877 - val_loss: 1.6422 - val_top_k_categorical_accuracy: 0.8853\n",
            "Epoch 39/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.3930 - top_k_categorical_accuracy: 0.9896 - val_loss: 1.8658 - val_top_k_categorical_accuracy: 0.8712\n",
            "Epoch 40/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.3819 - top_k_categorical_accuracy: 0.9901 - val_loss: 1.7961 - val_top_k_categorical_accuracy: 0.8764\n",
            "Epoch 41/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.3596 - top_k_categorical_accuracy: 0.9906 - val_loss: 1.5476 - val_top_k_categorical_accuracy: 0.8915\n",
            "Epoch 42/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.3450 - top_k_categorical_accuracy: 0.9913 - val_loss: 1.7989 - val_top_k_categorical_accuracy: 0.8819\n",
            "Epoch 43/75\n",
            "625/625 [==============================] - 87s 138ms/step - loss: 0.3354 - top_k_categorical_accuracy: 0.9920 - val_loss: 1.8840 - val_top_k_categorical_accuracy: 0.8740\n",
            "Epoch 44/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.3178 - top_k_categorical_accuracy: 0.9933 - val_loss: 1.7832 - val_top_k_categorical_accuracy: 0.8809\n",
            "Epoch 45/75\n",
            "625/625 [==============================] - 86s 138ms/step - loss: 0.2993 - top_k_categorical_accuracy: 0.9940 - val_loss: 2.0147 - val_top_k_categorical_accuracy: 0.8682\n",
            "Epoch 46/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.2863 - top_k_categorical_accuracy: 0.9941 - val_loss: 1.9043 - val_top_k_categorical_accuracy: 0.8692\n",
            "Epoch 47/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.2681 - top_k_categorical_accuracy: 0.9951 - val_loss: 1.9077 - val_top_k_categorical_accuracy: 0.8748\n",
            "Epoch 48/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.2622 - top_k_categorical_accuracy: 0.9949 - val_loss: 1.8734 - val_top_k_categorical_accuracy: 0.8888\n",
            "Epoch 49/75\n",
            "625/625 [==============================] - 86s 138ms/step - loss: 0.2491 - top_k_categorical_accuracy: 0.9957 - val_loss: 1.8063 - val_top_k_categorical_accuracy: 0.8890\n",
            "Epoch 50/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.2393 - top_k_categorical_accuracy: 0.9960 - val_loss: 1.7606 - val_top_k_categorical_accuracy: 0.8922\n",
            "Epoch 51/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.2262 - top_k_categorical_accuracy: 0.9967 - val_loss: 1.8331 - val_top_k_categorical_accuracy: 0.8884\n",
            "Epoch 52/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.2136 - top_k_categorical_accuracy: 0.9967 - val_loss: 1.8604 - val_top_k_categorical_accuracy: 0.8902\n",
            "Epoch 53/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.2057 - top_k_categorical_accuracy: 0.9972 - val_loss: 1.8586 - val_top_k_categorical_accuracy: 0.8874\n",
            "Epoch 54/75\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.1955 - top_k_categorical_accuracy: 0.9978 - val_loss: 1.9550 - val_top_k_categorical_accuracy: 0.8854\n",
            "Epoch 55/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.1877 - top_k_categorical_accuracy: 0.9979 - val_loss: 1.8264 - val_top_k_categorical_accuracy: 0.8897\n",
            "Epoch 56/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.1798 - top_k_categorical_accuracy: 0.9982 - val_loss: 1.8018 - val_top_k_categorical_accuracy: 0.8900\n",
            "Epoch 57/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.1683 - top_k_categorical_accuracy: 0.9980 - val_loss: 1.9675 - val_top_k_categorical_accuracy: 0.8824\n",
            "Epoch 58/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.1589 - top_k_categorical_accuracy: 0.9985 - val_loss: 1.8714 - val_top_k_categorical_accuracy: 0.8910\n",
            "Epoch 59/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.1549 - top_k_categorical_accuracy: 0.9985 - val_loss: 1.8378 - val_top_k_categorical_accuracy: 0.8896\n",
            "Epoch 60/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.1405 - top_k_categorical_accuracy: 0.9989 - val_loss: 1.6944 - val_top_k_categorical_accuracy: 0.9012\n",
            "Epoch 61/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.1359 - top_k_categorical_accuracy: 0.9987 - val_loss: 1.8996 - val_top_k_categorical_accuracy: 0.8898\n",
            "Epoch 62/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.1279 - top_k_categorical_accuracy: 0.9990 - val_loss: 1.8372 - val_top_k_categorical_accuracy: 0.8922\n",
            "Epoch 63/75\n",
            "625/625 [==============================] - 87s 139ms/step - loss: 0.1268 - top_k_categorical_accuracy: 0.9991 - val_loss: 1.8501 - val_top_k_categorical_accuracy: 0.8964\n",
            "Epoch 64/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.1177 - top_k_categorical_accuracy: 0.9992 - val_loss: 1.8805 - val_top_k_categorical_accuracy: 0.8975\n",
            "Epoch 65/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.1077 - top_k_categorical_accuracy: 0.9992 - val_loss: 1.8271 - val_top_k_categorical_accuracy: 0.9018\n",
            "Epoch 66/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.1050 - top_k_categorical_accuracy: 0.9991 - val_loss: 1.7965 - val_top_k_categorical_accuracy: 0.9013\n",
            "Epoch 67/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.1003 - top_k_categorical_accuracy: 0.9992 - val_loss: 1.9189 - val_top_k_categorical_accuracy: 0.8909\n",
            "Epoch 68/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.0920 - top_k_categorical_accuracy: 0.9994 - val_loss: 1.8807 - val_top_k_categorical_accuracy: 0.8977\n",
            "Epoch 69/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.0885 - top_k_categorical_accuracy: 0.9995 - val_loss: 1.8596 - val_top_k_categorical_accuracy: 0.8987\n",
            "Epoch 70/75\n",
            "625/625 [==============================] - 86s 138ms/step - loss: 0.0861 - top_k_categorical_accuracy: 0.9995 - val_loss: 1.7790 - val_top_k_categorical_accuracy: 0.9038\n",
            "Epoch 71/75\n",
            "625/625 [==============================] - 87s 139ms/step - loss: 0.0792 - top_k_categorical_accuracy: 0.9996 - val_loss: 1.7816 - val_top_k_categorical_accuracy: 0.9028\n",
            "Epoch 72/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.0765 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.8162 - val_top_k_categorical_accuracy: 0.9022\n",
            "Epoch 73/75\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.0733 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.8318 - val_top_k_categorical_accuracy: 0.9016\n",
            "Epoch 74/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.0694 - top_k_categorical_accuracy: 0.9995 - val_loss: 1.7942 - val_top_k_categorical_accuracy: 0.9029\n",
            "Epoch 75/75\n",
            "625/625 [==============================] - 82s 132ms/step - loss: 0.0695 - top_k_categorical_accuracy: 0.9996 - val_loss: 1.7955 - val_top_k_categorical_accuracy: 0.9029\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 1.7795 - top_k_categorical_accuracy: 0.9011\n",
            "\n",
            "Top 5 loss: 1.779516577720642\n",
            "Top 5 accuracy: 0.9010999798774719\n"
          ]
        }
      ],
      "source": [
        "#Danny Hong\n",
        "#ECE472 - Deep Learning\n",
        "#Assignment 4 Part 2: Classifying CIFAR-100\n",
        "\n",
        "#The model that is used here to classify CIFAR-100 is based on the Inception (Google Net) Model that is implemented on this site: \n",
        "#https://machinelearningknowledge.ai/googlenet-architecture-implementation-in-keras-with-cifar-10-dataset/\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.layers import Flatten, Input, Conv2D, AveragePooling2D, MaxPooling2D, BatchNormalization, concatenate, Activation, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import TopKCategoricalAccuracy \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#Reading in the CIFAR-100 files\n",
        "def get_data(data_file):\n",
        "    with open(data_file, 'rb') as file:\n",
        "        batch = pickle.load(file, encoding = 'bytes')\n",
        "        x_data = (batch[b'data'].reshape((len(batch[b'data']), 3, 32, 32)).transpose(0, 2, 3, 1)).astype('float32')\n",
        "        y_data = batch[b'fine_labels']\n",
        "    return x_data, y_data\n",
        "\n",
        "#Normalizing the x data\n",
        "def normalize_x_data(x_train, x_test):\n",
        "    eps = 1e-7\n",
        "    mean = np.mean(x_train,axis = (0, 1, 2, 3))\n",
        "    std = np.std(x_train,axis = (0, 1, 2, 3))\n",
        "    x_train = (x_train - mean)/(std + eps)\n",
        "    x_test = (x_test - mean)/(std + eps)\n",
        "    return x_train, x_test\n",
        "\n",
        "#Decaying the learning rate through a decay formula for each successive epoch\n",
        "def learning_rate_schedule(epoch):\n",
        "    max_epochs = epochs\n",
        "    base_learning_rate = 0.001\n",
        "    power = 1.0\n",
        "    learning_rate = base_learning_rate * (1 - (epoch / float(max_epochs))) ** power\n",
        "    \n",
        "    return learning_rate\n",
        "\n",
        "def conv_module(input, No_of_filters, filtersizeX, filtersizeY, stride, chanDim, padding = \"same\"):\n",
        "    input = Conv2D(No_of_filters,(filtersizeX, filtersizeY), strides = stride, padding = padding)(input)\n",
        "    input = BatchNormalization(axis = chanDim)(input)\n",
        "    input = Activation(\"relu\")(input)\n",
        "    \n",
        "    return input\n",
        "\n",
        "def inception_module(input, numK1x1, numK3x3, numk5x5, numPoolProj, chanDim):\n",
        "    conv_1x1 = conv_module(input, numK1x1, 1, 1, (1, 1), chanDim) \n",
        "    conv_3x3 = conv_module(input, numK3x3, 3, 3, (1, 1), chanDim)\n",
        "    conv_5x5 = conv_module(input, numk5x5, 5, 5, (1, 1), chanDim)\n",
        "    pool_proj = MaxPooling2D((3, 3), strides = (1, 1), padding='same')(input)\n",
        "    pool_proj = Conv2D(numPoolProj, (1, 1), padding = 'same', activation = 'relu')(pool_proj)\n",
        "    input = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=chanDim)\n",
        "    \n",
        "    return input\n",
        "\n",
        "def downsample_module(input, No_of_filters, chanDim):\n",
        "    conv_3x3 = conv_module(input, No_of_filters, 3, 3, (2, 2), chanDim, padding = \"valid\")\n",
        "    pool = MaxPooling2D((3, 3), strides = (2, 2))(input)\n",
        "    input = concatenate([conv_3x3, pool], axis = chanDim)\n",
        "    \n",
        "    return input\n",
        "\n",
        "num_classes = 100\n",
        "num_rows = 32\n",
        "num_columns = 32\n",
        "batch_size = 64\n",
        "epochs = 75\n",
        "weight_decay = 0.001\n",
        "\n",
        "def main():\n",
        "    x_train, y_train = get_data(data_file = 'train')\n",
        "    x_test, y_test = get_data(data_file = 'test')\n",
        "\n",
        "    x_train, x_test = x_train / 255, x_test / 255\n",
        "\n",
        "    x_train, x_test = normalize_x_data(x_train, x_test)\n",
        "    \n",
        "    y_train, y_test = tf.keras.utils.to_categorical(y_train, num_classes), tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "    \n",
        "    original_train_size = len(x_train)\n",
        "    new_train_size = len(x_train) - len(x_test)\n",
        "    x_val, y_val = x_train[new_train_size:original_train_size], y_train[new_train_size:original_train_size]\n",
        "    x_train, y_train = x_train[0:new_train_size], y_train[0:new_train_size]\n",
        "\n",
        "    data_generator = ImageDataGenerator(rotation_range = 15, width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True) \n",
        "    \n",
        "    train_generator = data_generator.flow(x_train, y_train, batch_size)\n",
        "    steps_per_epoch = len(x_train) // batch_size\n",
        "\n",
        "    #(Step 1) Defining the model input\n",
        "    inputs = Input(shape = (num_rows, num_columns, 3))\n",
        "\n",
        "    #First CONV module\n",
        "    x = conv_module(inputs, 96, 3, 3, (1, 1), -1)\n",
        "\n",
        "    #(Step 2) Two Inception modules followed by a downsample module\n",
        "    x = inception_module(x, 32, 32, 32, 32, -1)\n",
        "    x = inception_module(x, 32, 48, 48, 32, -1)\n",
        "    x = downsample_module(x, 80, -1)\n",
        "  \n",
        "    #(Step 3) Five Inception modules followed by a downsample module\n",
        "    x = inception_module(x, 112, 48, 32, 48, -1)\n",
        "    x = inception_module(x, 96, 64, 32, 32, -1)\n",
        "    x = inception_module(x, 80, 80, 32, 32, -1)\n",
        "    x = inception_module(x, 48, 96, 32, 32, -1)\n",
        "    x = inception_module(x, 112, 48, 32, 48, -1)\n",
        "    x = downsample_module(x, 96, -1)\n",
        "\n",
        "    #(Step 4) Two Inception modules followed\n",
        "    x = inception_module(x, 176, 160, 96, 96, -1)\n",
        "    x = inception_module(x, 176, 160, 96, 96, -1)\n",
        "  \n",
        "    #Global POOL and dropout\n",
        "    x = AveragePooling2D((7, 7))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    #(Step 5) Softmax classifier\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(num_classes)(x)\n",
        "    x = Activation(\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, x, name = \"googlenet\")\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    optimizer = Adam(learning_rate = 0.001, decay = 0, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08)\n",
        "    \n",
        "    model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = [TopKCategoricalAccuracy(k = 5)])\n",
        "\n",
        "    model.fit(train_generator, validation_data = (x_val, y_val), steps_per_epoch = steps_per_epoch, epochs = epochs, verbose = 1, callbacks = [LearningRateScheduler(learning_rate_schedule)])\n",
        "    \n",
        "    score = model.evaluate(x_test, y_test)\n",
        "    print('\\nTop 5 loss:', score[0])\n",
        "    print('Top 5 accuracy:', score[1])\n",
        "\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 7056.107684,
      "end_time": "2022-11-12T05:28:07.961102",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-11-12T03:30:31.853418",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
