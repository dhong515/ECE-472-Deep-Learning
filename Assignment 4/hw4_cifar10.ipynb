{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-10-03T15:50:05.059962Z",
          "iopub.status.busy": "2022-10-03T15:50:05.059586Z",
          "iopub.status.idle": "2022-10-03T17:04:34.669489Z",
          "shell.execute_reply": "2022-10-03T17:04:34.668392Z",
          "shell.execute_reply.started": "2022-10-03T15:50:05.059929Z"
        },
        "id": "Ffl9fNqV0fcH",
        "outputId": "f905dfa2-2064-44aa-e2c1-d5b9e68f0869",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 4,725,290\n",
            "Trainable params: 4,721,322\n",
            "Non-trainable params: 3,968\n",
            "_________________________________________________________________\n",
            "Epoch 1/225\n",
            "78/78 [==============================] - 23s 258ms/step - loss: 4.2688 - accuracy: 0.2893 - val_loss: 3.8511 - val_accuracy: 0.1100\n",
            "Epoch 2/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 3.0789 - accuracy: 0.3940 - val_loss: 3.3320 - val_accuracy: 0.1851\n",
            "Epoch 3/225\n",
            "78/78 [==============================] - 19s 247ms/step - loss: 2.5848 - accuracy: 0.4592 - val_loss: 3.2063 - val_accuracy: 0.1875\n",
            "Epoch 4/225\n",
            "78/78 [==============================] - 19s 246ms/step - loss: 2.3166 - accuracy: 0.5057 - val_loss: 2.7513 - val_accuracy: 0.3237\n",
            "Epoch 5/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 2.1966 - accuracy: 0.5323 - val_loss: 2.3975 - val_accuracy: 0.3812\n",
            "Epoch 6/225\n",
            "78/78 [==============================] - 19s 246ms/step - loss: 2.0792 - accuracy: 0.5533 - val_loss: 1.7636 - val_accuracy: 0.6107\n",
            "Epoch 7/225\n",
            "78/78 [==============================] - 18s 237ms/step - loss: 2.1403 - accuracy: 0.5607 - val_loss: 2.1067 - val_accuracy: 0.5159\n",
            "Epoch 8/225\n",
            "78/78 [==============================] - 19s 248ms/step - loss: 1.9325 - accuracy: 0.5874 - val_loss: 1.6810 - val_accuracy: 0.6262\n",
            "Epoch 9/225\n",
            "78/78 [==============================] - 21s 264ms/step - loss: 1.7879 - accuracy: 0.6159 - val_loss: 1.8500 - val_accuracy: 0.5818\n",
            "Epoch 10/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 1.6639 - accuracy: 0.6363 - val_loss: 1.6712 - val_accuracy: 0.6275\n",
            "Epoch 11/225\n",
            "78/78 [==============================] - 19s 245ms/step - loss: 1.5883 - accuracy: 0.6538 - val_loss: 1.4751 - val_accuracy: 0.6721\n",
            "Epoch 12/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 1.5124 - accuracy: 0.6687 - val_loss: 1.3909 - val_accuracy: 0.6972\n",
            "Epoch 13/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 1.4240 - accuracy: 0.6909 - val_loss: 1.8205 - val_accuracy: 0.5864\n",
            "Epoch 14/225\n",
            "78/78 [==============================] - 19s 246ms/step - loss: 1.4131 - accuracy: 0.7017 - val_loss: 1.3860 - val_accuracy: 0.6900\n",
            "Epoch 15/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 1.3297 - accuracy: 0.7156 - val_loss: 1.3638 - val_accuracy: 0.6959\n",
            "Epoch 16/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 1.2839 - accuracy: 0.7280 - val_loss: 1.2420 - val_accuracy: 0.7349\n",
            "Epoch 17/225\n",
            "78/78 [==============================] - 19s 246ms/step - loss: 1.2337 - accuracy: 0.7388 - val_loss: 1.1449 - val_accuracy: 0.7702\n",
            "Epoch 18/225\n",
            "78/78 [==============================] - 19s 242ms/step - loss: 1.2181 - accuracy: 0.7444 - val_loss: 1.1828 - val_accuracy: 0.7475\n",
            "Epoch 19/225\n",
            "78/78 [==============================] - 19s 245ms/step - loss: 1.1749 - accuracy: 0.7532 - val_loss: 1.2492 - val_accuracy: 0.7229\n",
            "Epoch 20/225\n",
            "78/78 [==============================] - 19s 246ms/step - loss: 1.1587 - accuracy: 0.7637 - val_loss: 1.1120 - val_accuracy: 0.7787\n",
            "Epoch 21/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 1.1275 - accuracy: 0.7679 - val_loss: 1.1131 - val_accuracy: 0.7639\n",
            "Epoch 22/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 1.1084 - accuracy: 0.7732 - val_loss: 1.0683 - val_accuracy: 0.7877\n",
            "Epoch 23/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 1.0997 - accuracy: 0.7782 - val_loss: 1.0425 - val_accuracy: 0.7905\n",
            "Epoch 24/225\n",
            "78/78 [==============================] - 19s 249ms/step - loss: 1.0778 - accuracy: 0.7799 - val_loss: 0.9893 - val_accuracy: 0.8137\n",
            "Epoch 25/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 1.0743 - accuracy: 0.7839 - val_loss: 1.0087 - val_accuracy: 0.8000\n",
            "Epoch 26/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 1.0369 - accuracy: 0.7949 - val_loss: 1.0411 - val_accuracy: 0.7937\n",
            "Epoch 27/225\n",
            "78/78 [==============================] - 19s 242ms/step - loss: 1.0206 - accuracy: 0.7972 - val_loss: 1.0799 - val_accuracy: 0.7774\n",
            "Epoch 28/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 1.0222 - accuracy: 0.7947 - val_loss: 0.9987 - val_accuracy: 0.7971\n",
            "Epoch 29/225\n",
            "78/78 [==============================] - 19s 246ms/step - loss: 1.0054 - accuracy: 0.8023 - val_loss: 0.9857 - val_accuracy: 0.8025\n",
            "Epoch 30/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 0.9999 - accuracy: 0.8018 - val_loss: 1.0544 - val_accuracy: 0.7870\n",
            "Epoch 31/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.9840 - accuracy: 0.8082 - val_loss: 1.0062 - val_accuracy: 0.8035\n",
            "Epoch 32/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.9860 - accuracy: 0.8082 - val_loss: 0.9496 - val_accuracy: 0.8183\n",
            "Epoch 33/225\n",
            "78/78 [==============================] - 20s 261ms/step - loss: 0.9643 - accuracy: 0.8149 - val_loss: 0.9105 - val_accuracy: 0.8327\n",
            "Epoch 34/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.9524 - accuracy: 0.8154 - val_loss: 0.9157 - val_accuracy: 0.8302\n",
            "Epoch 35/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 0.9572 - accuracy: 0.8175 - val_loss: 0.9464 - val_accuracy: 0.8207\n",
            "Epoch 36/225\n",
            "78/78 [==============================] - 18s 232ms/step - loss: 0.9528 - accuracy: 0.8142 - val_loss: 0.8686 - val_accuracy: 0.8465\n",
            "Epoch 37/225\n",
            "78/78 [==============================] - 18s 237ms/step - loss: 0.9315 - accuracy: 0.8222 - val_loss: 0.9660 - val_accuracy: 0.8160\n",
            "Epoch 38/225\n",
            "78/78 [==============================] - 20s 263ms/step - loss: 0.9368 - accuracy: 0.8239 - val_loss: 0.9216 - val_accuracy: 0.8306\n",
            "Epoch 39/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 0.9248 - accuracy: 0.8240 - val_loss: 0.9578 - val_accuracy: 0.8129\n",
            "Epoch 40/225\n",
            "78/78 [==============================] - 19s 248ms/step - loss: 0.9138 - accuracy: 0.8273 - val_loss: 0.9400 - val_accuracy: 0.8256\n",
            "Epoch 41/225\n",
            "78/78 [==============================] - 19s 247ms/step - loss: 0.9202 - accuracy: 0.8271 - val_loss: 0.8849 - val_accuracy: 0.8379\n",
            "Epoch 42/225\n",
            "78/78 [==============================] - 18s 234ms/step - loss: 0.9098 - accuracy: 0.8302 - val_loss: 0.9306 - val_accuracy: 0.8174\n",
            "Epoch 43/225\n",
            "78/78 [==============================] - 19s 241ms/step - loss: 0.9104 - accuracy: 0.8277 - val_loss: 0.9569 - val_accuracy: 0.8127\n",
            "Epoch 44/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.8994 - accuracy: 0.8290 - val_loss: 0.8731 - val_accuracy: 0.8413\n",
            "Epoch 45/225\n",
            "78/78 [==============================] - 20s 257ms/step - loss: 0.8989 - accuracy: 0.8317 - val_loss: 0.9142 - val_accuracy: 0.8273\n",
            "Epoch 46/225\n",
            "78/78 [==============================] - 19s 248ms/step - loss: 0.8846 - accuracy: 0.8358 - val_loss: 0.9313 - val_accuracy: 0.8211\n",
            "Epoch 47/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 0.8920 - accuracy: 0.8356 - val_loss: 0.9256 - val_accuracy: 0.8140\n",
            "Epoch 48/225\n",
            "78/78 [==============================] - 19s 242ms/step - loss: 0.8759 - accuracy: 0.8380 - val_loss: 0.8701 - val_accuracy: 0.8366\n",
            "Epoch 49/225\n",
            "78/78 [==============================] - 19s 247ms/step - loss: 0.8723 - accuracy: 0.8377 - val_loss: 0.9441 - val_accuracy: 0.8128\n",
            "Epoch 50/225\n",
            "78/78 [==============================] - 18s 237ms/step - loss: 0.8664 - accuracy: 0.8420 - val_loss: 0.9779 - val_accuracy: 0.8061\n",
            "Epoch 51/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 0.8659 - accuracy: 0.8402 - val_loss: 0.7953 - val_accuracy: 0.8635\n",
            "Epoch 52/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 0.8613 - accuracy: 0.8418 - val_loss: 0.9496 - val_accuracy: 0.8161\n",
            "Epoch 53/225\n",
            "78/78 [==============================] - 19s 235ms/step - loss: 0.8553 - accuracy: 0.8427 - val_loss: 0.8716 - val_accuracy: 0.8354\n",
            "Epoch 54/225\n",
            "78/78 [==============================] - 20s 259ms/step - loss: 0.8549 - accuracy: 0.8403 - val_loss: 0.8274 - val_accuracy: 0.8478\n",
            "Epoch 55/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.8413 - accuracy: 0.8482 - val_loss: 0.8122 - val_accuracy: 0.8590\n",
            "Epoch 56/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.8510 - accuracy: 0.8441 - val_loss: 0.8601 - val_accuracy: 0.8416\n",
            "Epoch 57/225\n",
            "78/78 [==============================] - 19s 245ms/step - loss: 0.8525 - accuracy: 0.8426 - val_loss: 0.8281 - val_accuracy: 0.8494\n",
            "Epoch 58/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.8400 - accuracy: 0.8464 - val_loss: 0.8851 - val_accuracy: 0.8328\n",
            "Epoch 59/225\n",
            "78/78 [==============================] - 19s 246ms/step - loss: 0.8368 - accuracy: 0.8474 - val_loss: 0.8490 - val_accuracy: 0.8410\n",
            "Epoch 60/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 0.8308 - accuracy: 0.8496 - val_loss: 0.8682 - val_accuracy: 0.8367\n",
            "Epoch 61/225\n",
            "78/78 [==============================] - ETA: 0s - loss: 0.8327 - accuracy: 0.8486Epoch 62/225\n",
            "78/78 [==============================] - 20s 253ms/step - loss: 0.8223 - accuracy: 0.8497 - val_loss: 0.9597 - val_accuracy: 0.8169\n",
            "Epoch 63/225\n",
            "78/78 [==============================] - 19s 241ms/step - loss: 0.8180 - accuracy: 0.8525 - val_loss: 0.8209 - val_accuracy: 0.8500\n",
            "Epoch 64/225\n",
            "78/78 [==============================] - 19s 245ms/step - loss: 0.8195 - accuracy: 0.8538 - val_loss: 0.9372 - val_accuracy: 0.8144\n",
            "Epoch 65/225\n",
            "78/78 [==============================] - 20s 252ms/step - loss: 0.8111 - accuracy: 0.8546 - val_loss: 0.7922 - val_accuracy: 0.8572\n",
            "Epoch 66/225\n",
            "78/78 [==============================] - 20s 252ms/step - loss: 0.8199 - accuracy: 0.8509 - val_loss: 0.8833 - val_accuracy: 0.8311\n",
            "Epoch 67/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.8075 - accuracy: 0.8528 - val_loss: 1.0537 - val_accuracy: 0.7788\n",
            "Epoch 68/225\n",
            "78/78 [==============================] - 18s 234ms/step - loss: 0.8082 - accuracy: 0.8541 - val_loss: 0.9602 - val_accuracy: 0.8098\n",
            "Epoch 69/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.8045 - accuracy: 0.8520 - val_loss: 0.8161 - val_accuracy: 0.8512\n",
            "Epoch 70/225\n",
            "78/78 [==============================] - 20s 252ms/step - loss: 0.8018 - accuracy: 0.8558 - val_loss: 0.8310 - val_accuracy: 0.8468\n",
            "Epoch 71/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.8006 - accuracy: 0.8527 - val_loss: 0.7639 - val_accuracy: 0.8669\n",
            "Epoch 72/225\n",
            "78/78 [==============================] - 19s 246ms/step - loss: 0.7947 - accuracy: 0.8547 - val_loss: 0.8535 - val_accuracy: 0.8378\n",
            "Epoch 73/225\n",
            "78/78 [==============================] - 19s 245ms/step - loss: 0.7919 - accuracy: 0.8579 - val_loss: 0.8553 - val_accuracy: 0.8317\n",
            "Epoch 74/225\n",
            "78/78 [==============================] - 18s 237ms/step - loss: 0.7886 - accuracy: 0.8576 - val_loss: 0.8343 - val_accuracy: 0.8484\n",
            "Epoch 75/225\n",
            "78/78 [==============================] - 19s 245ms/step - loss: 0.7751 - accuracy: 0.8595 - val_loss: 0.8177 - val_accuracy: 0.8519\n",
            "Epoch 76/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.7863 - accuracy: 0.8584 - val_loss: 0.7642 - val_accuracy: 0.8616\n",
            "Epoch 77/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.6997 - accuracy: 0.8806 - val_loss: 0.7165 - val_accuracy: 0.8712\n",
            "Epoch 78/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 0.6625 - accuracy: 0.8865 - val_loss: 0.6636 - val_accuracy: 0.8850\n",
            "Epoch 79/225\n",
            "78/78 [==============================] - 20s 254ms/step - loss: 0.6462 - accuracy: 0.8884 - val_loss: 0.7070 - val_accuracy: 0.8684\n",
            "Epoch 80/225\n",
            "78/78 [==============================] - 19s 249ms/step - loss: 0.6283 - accuracy: 0.8908 - val_loss: 0.6967 - val_accuracy: 0.8663\n",
            "Epoch 81/225\n",
            "78/78 [==============================] - 20s 263ms/step - loss: 0.6191 - accuracy: 0.8924 - val_loss: 0.6839 - val_accuracy: 0.8708\n",
            "Epoch 82/225\n",
            "78/78 [==============================] - 18s 237ms/step - loss: 0.6050 - accuracy: 0.8945 - val_loss: 0.6714 - val_accuracy: 0.8713\n",
            "Epoch 83/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 0.5959 - accuracy: 0.8952 - val_loss: 0.6370 - val_accuracy: 0.8772\n",
            "Epoch 84/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 0.5896 - accuracy: 0.8970 - val_loss: 0.6530 - val_accuracy: 0.8768\n",
            "Epoch 85/225\n",
            "78/78 [==============================] - 19s 241ms/step - loss: 0.5850 - accuracy: 0.8949 - val_loss: 0.6228 - val_accuracy: 0.8815\n",
            "Epoch 86/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 0.5793 - accuracy: 0.8969 - val_loss: 0.6363 - val_accuracy: 0.8813\n",
            "Epoch 87/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.5750 - accuracy: 0.8990 - val_loss: 0.6625 - val_accuracy: 0.8738\n",
            "Epoch 88/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.5691 - accuracy: 0.8981 - val_loss: 0.6503 - val_accuracy: 0.8736\n",
            "Epoch 89/225\n",
            "78/78 [==============================] - 19s 245ms/step - loss: 0.5604 - accuracy: 0.9002 - val_loss: 0.6144 - val_accuracy: 0.8882\n",
            "Epoch 90/225\n",
            "78/78 [==============================] - 20s 253ms/step - loss: 0.5658 - accuracy: 0.8985 - val_loss: 0.6058 - val_accuracy: 0.8842\n",
            "Epoch 91/225\n",
            "78/78 [==============================] - 19s 245ms/step - loss: 0.5631 - accuracy: 0.8995 - val_loss: 0.6707 - val_accuracy: 0.8686\n",
            "Epoch 92/225\n",
            "78/78 [==============================] - 19s 248ms/step - loss: 0.5600 - accuracy: 0.8998 - val_loss: 0.6319 - val_accuracy: 0.8783\n",
            "Epoch 93/225\n",
            "78/78 [==============================] - 20s 252ms/step - loss: 0.5551 - accuracy: 0.8993 - val_loss: 0.6216 - val_accuracy: 0.8817\n",
            "Epoch 94/225\n",
            "78/78 [==============================] - 21s 264ms/step - loss: 0.5543 - accuracy: 0.9005 - val_loss: 0.6029 - val_accuracy: 0.8834\n",
            "Epoch 95/225\n",
            "78/78 [==============================] - 19s 249ms/step - loss: 0.5522 - accuracy: 0.9014 - val_loss: 0.6158 - val_accuracy: 0.8847\n",
            "Epoch 96/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 0.5447 - accuracy: 0.9009 - val_loss: 0.6288 - val_accuracy: 0.8776\n",
            "Epoch 97/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.5459 - accuracy: 0.9014 - val_loss: 0.5954 - val_accuracy: 0.8915\n",
            "Epoch 98/225\n",
            "78/78 [==============================] - 19s 241ms/step - loss: 0.5475 - accuracy: 0.9004 - val_loss: 0.6488 - val_accuracy: 0.8728\n",
            "Epoch 99/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 0.5416 - accuracy: 0.9025 - val_loss: 0.6514 - val_accuracy: 0.8741\n",
            "Epoch 100/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.5380 - accuracy: 0.9019 - val_loss: 0.5896 - val_accuracy: 0.8905\n",
            "Epoch 101/225\n",
            "78/78 [==============================] - 19s 248ms/step - loss: 0.5358 - accuracy: 0.9035 - val_loss: 0.6048 - val_accuracy: 0.8864\n",
            "Epoch 102/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.5028 - accuracy: 0.9138 - val_loss: 0.5458 - val_accuracy: 0.9008\n",
            "Epoch 103/225\n",
            "78/78 [==============================] - 19s 242ms/step - loss: 0.4862 - accuracy: 0.9168 - val_loss: 0.5515 - val_accuracy: 0.8993\n",
            "Epoch 104/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 0.4770 - accuracy: 0.9196 - val_loss: 0.5471 - val_accuracy: 0.8986\n",
            "Epoch 105/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 0.4766 - accuracy: 0.9165 - val_loss: 0.5389 - val_accuracy: 0.9005\n",
            "Epoch 106/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 0.4668 - accuracy: 0.9196 - val_loss: 0.6014 - val_accuracy: 0.8823\n",
            "Epoch 107/225\n",
            "78/78 [==============================] - 19s 250ms/step - loss: 0.4634 - accuracy: 0.9203 - val_loss: 0.5715 - val_accuracy: 0.8894\n",
            "Epoch 108/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 0.4597 - accuracy: 0.9202 - val_loss: 0.5566 - val_accuracy: 0.8935\n",
            "Epoch 109/225\n",
            "78/78 [==============================] - 19s 247ms/step - loss: 0.4547 - accuracy: 0.9216 - val_loss: 0.5760 - val_accuracy: 0.8907\n",
            "Epoch 110/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 0.4516 - accuracy: 0.9223 - val_loss: 0.5534 - val_accuracy: 0.8922\n",
            "Epoch 111/225\n",
            "78/78 [==============================] - 19s 246ms/step - loss: 0.4486 - accuracy: 0.9213 - val_loss: 0.5447 - val_accuracy: 0.8964\n",
            "Epoch 112/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.4420 - accuracy: 0.9258 - val_loss: 0.5813 - val_accuracy: 0.8863\n",
            "Epoch 113/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.4471 - accuracy: 0.9225 - val_loss: 0.5816 - val_accuracy: 0.8904\n",
            "Epoch 114/225\n",
            "78/78 [==============================] - 19s 248ms/step - loss: 0.4369 - accuracy: 0.9250 - val_loss: 0.5688 - val_accuracy: 0.8916\n",
            "Epoch 115/225\n",
            "78/78 [==============================] - 18s 237ms/step - loss: 0.4396 - accuracy: 0.9236 - val_loss: 0.5255 - val_accuracy: 0.9013\n",
            "Epoch 116/225\n",
            "78/78 [==============================] - 19s 248ms/step - loss: 0.4318 - accuracy: 0.9244 - val_loss: 0.5421 - val_accuracy: 0.8981\n",
            "Epoch 117/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.4378 - accuracy: 0.9225 - val_loss: 0.5493 - val_accuracy: 0.8923\n",
            "Epoch 118/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.4317 - accuracy: 0.9236 - val_loss: 0.4932 - val_accuracy: 0.9100\n",
            "Epoch 119/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.4331 - accuracy: 0.9232 - val_loss: 0.5319 - val_accuracy: 0.8983\n",
            "Epoch 120/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.4240 - accuracy: 0.9257 - val_loss: 0.5232 - val_accuracy: 0.8995\n",
            "Epoch 121/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 0.4265 - accuracy: 0.9258 - val_loss: 0.5838 - val_accuracy: 0.8819\n",
            "Epoch 122/225\n",
            "78/78 [==============================] - 18s 232ms/step - loss: 0.4230 - accuracy: 0.9272 - val_loss: 0.5450 - val_accuracy: 0.8919\n",
            "Epoch 123/225\n",
            "78/78 [==============================] - 18s 237ms/step - loss: 0.4172 - accuracy: 0.9285 - val_loss: 0.5442 - val_accuracy: 0.8948\n",
            "Epoch 124/225\n",
            "78/78 [==============================] - 19s 242ms/step - loss: 0.4206 - accuracy: 0.9267 - val_loss: 0.5083 - val_accuracy: 0.9013\n",
            "Epoch 125/225\n",
            "78/78 [==============================] - 18s 234ms/step - loss: 0.4193 - accuracy: 0.9279 - val_loss: 0.5406 - val_accuracy: 0.8952\n",
            "Epoch 126/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 0.4228 - accuracy: 0.9260 - val_loss: 0.5157 - val_accuracy: 0.8992\n",
            "Epoch 127/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 0.3892 - accuracy: 0.9354 - val_loss: 0.5197 - val_accuracy: 0.9013\n",
            "Epoch 128/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.3742 - accuracy: 0.9389 - val_loss: 0.5135 - val_accuracy: 0.9031\n",
            "Epoch 129/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.3728 - accuracy: 0.9392 - val_loss: 0.5056 - val_accuracy: 0.9060\n",
            "Epoch 130/225\n",
            "78/78 [==============================] - 19s 241ms/step - loss: 0.3669 - accuracy: 0.9420 - val_loss: 0.5041 - val_accuracy: 0.9055\n",
            "Epoch 131/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 0.3614 - accuracy: 0.9426 - val_loss: 0.4929 - val_accuracy: 0.9080\n",
            "Epoch 132/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 0.3581 - accuracy: 0.9423 - val_loss: 0.4894 - val_accuracy: 0.9063\n",
            "Epoch 133/225\n",
            "78/78 [==============================] - 19s 241ms/step - loss: 0.3533 - accuracy: 0.9435 - val_loss: 0.4943 - val_accuracy: 0.9090\n",
            "Epoch 134/225\n",
            "78/78 [==============================] - 18s 234ms/step - loss: 0.3499 - accuracy: 0.9466 - val_loss: 0.4896 - val_accuracy: 0.9096\n",
            "Epoch 135/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 0.3501 - accuracy: 0.9452 - val_loss: 0.5031 - val_accuracy: 0.9058\n",
            "Epoch 136/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 0.3411 - accuracy: 0.9471 - val_loss: 0.4893 - val_accuracy: 0.9104\n",
            "Epoch 137/225\n",
            "78/78 [==============================] - 18s 232ms/step - loss: 0.3413 - accuracy: 0.9459 - val_loss: 0.4939 - val_accuracy: 0.9078\n",
            "Epoch 138/225\n",
            "78/78 [==============================] - 19s 247ms/step - loss: 0.3413 - accuracy: 0.9466 - val_loss: 0.4997 - val_accuracy: 0.9056\n",
            "Epoch 139/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.3347 - accuracy: 0.9484 - val_loss: 0.4934 - val_accuracy: 0.9078\n",
            "Epoch 140/225\n",
            "78/78 [==============================] - 18s 233ms/step - loss: 0.3328 - accuracy: 0.9486 - val_loss: 0.4803 - val_accuracy: 0.9095\n",
            "Epoch 141/225\n",
            "78/78 [==============================] - 19s 241ms/step - loss: 0.3333 - accuracy: 0.9486 - val_loss: 0.4823 - val_accuracy: 0.9099\n",
            "Epoch 142/225\n",
            "78/78 [==============================] - 18s 231ms/step - loss: 0.3309 - accuracy: 0.9481 - val_loss: 0.4908 - val_accuracy: 0.9063\n",
            "Epoch 143/225\n",
            "78/78 [==============================] - 19s 249ms/step - loss: 0.3276 - accuracy: 0.9490 - val_loss: 0.4792 - val_accuracy: 0.9105\n",
            "Epoch 144/225\n",
            "78/78 [==============================] - 19s 250ms/step - loss: 0.3230 - accuracy: 0.9514 - val_loss: 0.4921 - val_accuracy: 0.9063\n",
            "Epoch 145/225\n",
            "78/78 [==============================] - 18s 232ms/step - loss: 0.3211 - accuracy: 0.9506 - val_loss: 0.4830 - val_accuracy: 0.9070\n",
            "Epoch 146/225\n",
            "78/78 [==============================] - 18s 237ms/step - loss: 0.3211 - accuracy: 0.9497 - val_loss: 0.4935 - val_accuracy: 0.9054\n",
            "Epoch 147/225\n",
            "78/78 [==============================] - 18s 232ms/step - loss: 0.3213 - accuracy: 0.9502 - val_loss: 0.4811 - val_accuracy: 0.9090\n",
            "Epoch 148/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 0.3223 - accuracy: 0.9491 - val_loss: 0.4881 - val_accuracy: 0.9081\n",
            "Epoch 149/225\n",
            "78/78 [==============================] - 19s 242ms/step - loss: 0.3179 - accuracy: 0.9507 - val_loss: 0.4620 - val_accuracy: 0.9122\n",
            "Epoch 150/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.3193 - accuracy: 0.9494 - val_loss: 0.4718 - val_accuracy: 0.9097\n",
            "Epoch 151/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.3147 - accuracy: 0.9515 - val_loss: 0.4855 - val_accuracy: 0.9075\n",
            "Epoch 152/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 0.3081 - accuracy: 0.9534 - val_loss: 0.4663 - val_accuracy: 0.9125\n",
            "Epoch 153/225\n",
            "78/78 [==============================] - 18s 231ms/step - loss: 0.3027 - accuracy: 0.9555 - val_loss: 0.4792 - val_accuracy: 0.9096\n",
            "Epoch 154/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.3001 - accuracy: 0.9556 - val_loss: 0.4666 - val_accuracy: 0.9138\n",
            "Epoch 155/225\n",
            "78/78 [==============================] - 18s 234ms/step - loss: 0.2975 - accuracy: 0.9567 - val_loss: 0.4669 - val_accuracy: 0.9124\n",
            "Epoch 156/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 0.3015 - accuracy: 0.9551 - val_loss: 0.4673 - val_accuracy: 0.9123\n",
            "Epoch 157/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.2923 - accuracy: 0.9571 - val_loss: 0.4685 - val_accuracy: 0.9123\n",
            "Epoch 158/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 0.2943 - accuracy: 0.9573 - val_loss: 0.4738 - val_accuracy: 0.9101\n",
            "Epoch 159/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 0.2896 - accuracy: 0.9576 - val_loss: 0.4817 - val_accuracy: 0.9088\n",
            "Epoch 160/225\n",
            "78/78 [==============================] - 18s 232ms/step - loss: 0.2963 - accuracy: 0.9552 - val_loss: 0.4635 - val_accuracy: 0.9116\n",
            "Epoch 161/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 0.2924 - accuracy: 0.9569 - val_loss: 0.4569 - val_accuracy: 0.9146\n",
            "Epoch 162/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.2931 - accuracy: 0.9569 - val_loss: 0.4766 - val_accuracy: 0.9079\n",
            "Epoch 163/225\n",
            "78/78 [==============================] - 18s 231ms/step - loss: 0.2891 - accuracy: 0.9564 - val_loss: 0.4694 - val_accuracy: 0.9114\n",
            "Epoch 164/225\n",
            "78/78 [==============================] - 19s 242ms/step - loss: 0.2921 - accuracy: 0.9557 - val_loss: 0.4804 - val_accuracy: 0.9077\n",
            "Epoch 165/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.2892 - accuracy: 0.9567 - val_loss: 0.4643 - val_accuracy: 0.9117\n",
            "Epoch 166/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.2855 - accuracy: 0.9580 - val_loss: 0.4572 - val_accuracy: 0.9131\n",
            "Epoch 167/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.2822 - accuracy: 0.9595 - val_loss: 0.4694 - val_accuracy: 0.9092\n",
            "Epoch 168/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.2865 - accuracy: 0.9567 - val_loss: 0.4618 - val_accuracy: 0.9111\n",
            "Epoch 169/225\n",
            "78/78 [==============================] - 18s 233ms/step - loss: 0.2808 - accuracy: 0.9596 - val_loss: 0.4582 - val_accuracy: 0.9125\n",
            "Epoch 170/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 0.2801 - accuracy: 0.9590 - val_loss: 0.4594 - val_accuracy: 0.9135\n",
            "Epoch 171/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.2764 - accuracy: 0.9598 - val_loss: 0.4605 - val_accuracy: 0.9122\n",
            "Epoch 172/225\n",
            "78/78 [==============================] - 18s 237ms/step - loss: 0.2818 - accuracy: 0.9585 - val_loss: 0.4671 - val_accuracy: 0.9109\n",
            "Epoch 173/225\n",
            "78/78 [==============================] - 19s 242ms/step - loss: 0.2784 - accuracy: 0.9589 - val_loss: 0.4561 - val_accuracy: 0.9122\n",
            "Epoch 174/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.2742 - accuracy: 0.9608 - val_loss: 0.4640 - val_accuracy: 0.9120\n",
            "Epoch 175/225\n",
            "78/78 [==============================] - 19s 242ms/step - loss: 0.2773 - accuracy: 0.9593 - val_loss: 0.4684 - val_accuracy: 0.9099\n",
            "Epoch 176/225\n",
            "78/78 [==============================] - 18s 233ms/step - loss: 0.2774 - accuracy: 0.9589 - val_loss: 0.4617 - val_accuracy: 0.9110\n",
            "Epoch 177/225\n",
            "78/78 [==============================] - 18s 230ms/step - loss: 0.2703 - accuracy: 0.9612 - val_loss: 0.4567 - val_accuracy: 0.9127\n",
            "Epoch 178/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.2693 - accuracy: 0.9626 - val_loss: 0.4710 - val_accuracy: 0.9099\n",
            "Epoch 179/225\n",
            "78/78 [==============================] - 18s 233ms/step - loss: 0.2668 - accuracy: 0.9616 - val_loss: 0.4622 - val_accuracy: 0.9113\n",
            "Epoch 180/225\n",
            "78/78 [==============================] - 19s 242ms/step - loss: 0.2706 - accuracy: 0.9621 - val_loss: 0.4694 - val_accuracy: 0.9100\n",
            "Epoch 181/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.2671 - accuracy: 0.9624 - val_loss: 0.4595 - val_accuracy: 0.9114\n",
            "Epoch 182/225\n",
            "78/78 [==============================] - 18s 228ms/step - loss: 0.2656 - accuracy: 0.9610 - val_loss: 0.4615 - val_accuracy: 0.9113\n",
            "Epoch 183/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.2678 - accuracy: 0.9624 - val_loss: 0.4685 - val_accuracy: 0.9110\n",
            "Epoch 184/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.2637 - accuracy: 0.9620 - val_loss: 0.4638 - val_accuracy: 0.9116\n",
            "Epoch 185/225\n",
            "78/78 [==============================] - 19s 241ms/step - loss: 0.2615 - accuracy: 0.9647 - val_loss: 0.4640 - val_accuracy: 0.9118\n",
            "Epoch 186/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.2657 - accuracy: 0.9628 - val_loss: 0.4595 - val_accuracy: 0.9125\n",
            "Epoch 187/225\n",
            "78/78 [==============================] - 18s 232ms/step - loss: 0.2620 - accuracy: 0.9634 - val_loss: 0.4580 - val_accuracy: 0.9127\n",
            "Epoch 188/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.2621 - accuracy: 0.9638 - val_loss: 0.4615 - val_accuracy: 0.9132\n",
            "Epoch 189/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.2645 - accuracy: 0.9611 - val_loss: 0.4572 - val_accuracy: 0.9137\n",
            "Epoch 190/225\n",
            "78/78 [==============================] - 19s 244ms/step - loss: 0.2616 - accuracy: 0.9624 - val_loss: 0.4607 - val_accuracy: 0.9124\n",
            "Epoch 191/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 0.2589 - accuracy: 0.9645 - val_loss: 0.4583 - val_accuracy: 0.9129\n",
            "Epoch 192/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.2595 - accuracy: 0.9640 - val_loss: 0.4651 - val_accuracy: 0.9112\n",
            "Epoch 193/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 0.2583 - accuracy: 0.9638 - val_loss: 0.4610 - val_accuracy: 0.9105\n",
            "Epoch 194/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 0.2575 - accuracy: 0.9645 - val_loss: 0.4543 - val_accuracy: 0.9137\n",
            "Epoch 195/225\n",
            "78/78 [==============================] - 18s 234ms/step - loss: 0.2596 - accuracy: 0.9642 - val_loss: 0.4545 - val_accuracy: 0.9129\n",
            "Epoch 196/225\n",
            "78/78 [==============================] - 19s 238ms/step - loss: 0.2570 - accuracy: 0.9648 - val_loss: 0.4574 - val_accuracy: 0.9125\n",
            "Epoch 197/225\n",
            "78/78 [==============================] - 18s 228ms/step - loss: 0.2568 - accuracy: 0.9633 - val_loss: 0.4548 - val_accuracy: 0.9132\n",
            "Epoch 198/225\n",
            "78/78 [==============================] - 18s 233ms/step - loss: 0.2507 - accuracy: 0.9662 - val_loss: 0.4559 - val_accuracy: 0.9129\n",
            "Epoch 199/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.2540 - accuracy: 0.9653 - val_loss: 0.4609 - val_accuracy: 0.9120\n",
            "Epoch 200/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.2544 - accuracy: 0.9640 - val_loss: 0.4560 - val_accuracy: 0.9131\n",
            "Epoch 201/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.2561 - accuracy: 0.9647 - val_loss: 0.4549 - val_accuracy: 0.9141\n",
            "Epoch 202/225\n",
            "78/78 [==============================] - 19s 249ms/step - loss: 0.2543 - accuracy: 0.9642 - val_loss: 0.4603 - val_accuracy: 0.9123\n",
            "Epoch 203/225\n",
            "78/78 [==============================] - 18s 234ms/step - loss: 0.2584 - accuracy: 0.9628 - val_loss: 0.4595 - val_accuracy: 0.9109\n",
            "Epoch 204/225\n",
            "78/78 [==============================] - 19s 243ms/step - loss: 0.2532 - accuracy: 0.9638 - val_loss: 0.4506 - val_accuracy: 0.9139\n",
            "Epoch 205/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.2525 - accuracy: 0.9654 - val_loss: 0.4459 - val_accuracy: 0.9154\n",
            "Epoch 206/225\n",
            "78/78 [==============================] - 19s 240ms/step - loss: 0.2510 - accuracy: 0.9650 - val_loss: 0.4530 - val_accuracy: 0.9134\n",
            "Epoch 207/225\n",
            "78/78 [==============================] - 19s 241ms/step - loss: 0.2528 - accuracy: 0.9652 - val_loss: 0.4532 - val_accuracy: 0.9131\n",
            "Epoch 208/225\n",
            "78/78 [==============================] - 20s 253ms/step - loss: 0.2509 - accuracy: 0.9651 - val_loss: 0.4583 - val_accuracy: 0.9137\n",
            "Epoch 209/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.2497 - accuracy: 0.9663 - val_loss: 0.4508 - val_accuracy: 0.9147\n",
            "Epoch 210/225\n",
            "78/78 [==============================] - 18s 230ms/step - loss: 0.2466 - accuracy: 0.9664 - val_loss: 0.4592 - val_accuracy: 0.9125\n",
            "Epoch 211/225\n",
            "78/78 [==============================] - 19s 241ms/step - loss: 0.2487 - accuracy: 0.9648 - val_loss: 0.4561 - val_accuracy: 0.9133\n",
            "Epoch 212/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 0.2482 - accuracy: 0.9656 - val_loss: 0.4593 - val_accuracy: 0.9107\n",
            "Epoch 213/225\n",
            "78/78 [==============================] - 19s 247ms/step - loss: 0.2497 - accuracy: 0.9651 - val_loss: 0.4546 - val_accuracy: 0.9117\n",
            "Epoch 214/225\n",
            "78/78 [==============================] - 19s 239ms/step - loss: 0.2498 - accuracy: 0.9655 - val_loss: 0.4482 - val_accuracy: 0.9123\n",
            "Epoch 215/225\n",
            "78/78 [==============================] - 18s 233ms/step - loss: 0.2438 - accuracy: 0.9660 - val_loss: 0.4558 - val_accuracy: 0.9127\n",
            "Epoch 216/225\n",
            "78/78 [==============================] - 18s 231ms/step - loss: 0.2454 - accuracy: 0.9662 - val_loss: 0.4576 - val_accuracy: 0.9135\n",
            "Epoch 217/225\n",
            "78/78 [==============================] - 19s 242ms/step - loss: 0.2469 - accuracy: 0.9653 - val_loss: 0.4575 - val_accuracy: 0.9135\n",
            "Epoch 218/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.2461 - accuracy: 0.9657 - val_loss: 0.4603 - val_accuracy: 0.9112\n",
            "Epoch 219/225\n",
            "78/78 [==============================] - 18s 234ms/step - loss: 0.2475 - accuracy: 0.9654 - val_loss: 0.4531 - val_accuracy: 0.9126\n",
            "Epoch 220/225\n",
            "78/78 [==============================] - 18s 237ms/step - loss: 0.2461 - accuracy: 0.9660 - val_loss: 0.4544 - val_accuracy: 0.9128\n",
            "Epoch 221/225\n",
            "78/78 [==============================] - 18s 236ms/step - loss: 0.2447 - accuracy: 0.9656 - val_loss: 0.4571 - val_accuracy: 0.9120\n",
            "Epoch 222/225\n",
            "78/78 [==============================] - 18s 237ms/step - loss: 0.2414 - accuracy: 0.9675 - val_loss: 0.4555 - val_accuracy: 0.9134\n",
            "Epoch 223/225\n",
            "78/78 [==============================] - 18s 235ms/step - loss: 0.2419 - accuracy: 0.9661 - val_loss: 0.4630 - val_accuracy: 0.9111\n",
            "Epoch 224/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 0.2425 - accuracy: 0.9664 - val_loss: 0.4617 - val_accuracy: 0.9119\n",
            "Epoch 225/225\n",
            "78/78 [==============================] - 19s 237ms/step - loss: 0.2490 - accuracy: 0.9645 - val_loss: 0.4569 - val_accuracy: 0.9136\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4874 - accuracy: 0.9117\n",
            "\n",
            "Test loss: 0.48736539483070374\n",
            "Test accuracy: 0.9117000102996826\n"
          ]
        }
      ],
      "source": [
        "#Danny Hong\n",
        "#ECE472 - Deep Learning\n",
        "#Assignment 4 Part 1: Classifying CIFAR-10\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, MaxPool2D, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "#Reading in batch data for the training sets for the CIFAR-10 dataset:\n",
        "def get_batches(data_batch_files):\n",
        "  for i in range(len(data_batch_files)):\n",
        "    with open(data_batch_files[i], 'rb') as file:\n",
        "      batch = pickle.load(file, encoding='bytes')\n",
        "      if i == 0:\n",
        "        x_train = (batch[b'data'].reshape((len(batch[b'data']), 3, 32, 32)).transpose(0, 2, 3, 1)).astype('float32')\n",
        "        y_train = batch[b'labels']\n",
        "      else:\n",
        "        x_train_temp = (batch[b'data'].reshape((len(batch[b'data']), 3, 32, 32)).transpose(0, 2, 3, 1)).astype('float32')\n",
        "        y_train_temp = batch[b'labels']\n",
        "        x_train = np.concatenate((x_train, x_train_temp), axis=0)\n",
        "        y_train = np.concatenate((y_train, y_train_temp), axis=0)\n",
        "\n",
        "  return x_train, y_train\n",
        "\n",
        "#Reading in the files for the CIFAR-10 dataset\n",
        "def get_data(data_file):\n",
        "  with open(data_file, 'rb') as file:\n",
        "    batch = pickle.load(file, encoding='bytes')\n",
        "    x_data = (batch[b'data'].reshape((len(batch[b'data']), 3, 32, 32)).transpose(0, 2, 3, 1)).astype('float32')\n",
        "    y_data = batch[b'labels']\n",
        "\n",
        "  return x_data, y_data\n",
        "\n",
        "#Normalizing the x data: \n",
        "def normalize_x_data(x_train, x_test):\n",
        "  eps = 1e-7\n",
        "  mean = np.mean(x_train,axis = (0, 1, 2, 3))\n",
        "  std = np.std(x_train,axis = (0, 1, 2, 3))\n",
        "  x_train = (x_train - mean)/(std + eps)\n",
        "  x_test = (x_test - mean)/(std + eps)\n",
        "\n",
        "  return x_train, x_test\n",
        "\n",
        "#Decaying the learning rate decay over time\n",
        "def learning_rate_schedule(epoch):\n",
        "  learning_rate = 0.001\n",
        "  if epoch > 75:\n",
        "    learning_rate = 0.0005 \n",
        "  if epoch > 100:\n",
        "    learning_rate = 0.0003 \n",
        "  if epoch > 125:\n",
        "    learning_rate = 0.0001\n",
        "  if epoch > 150:\n",
        "    learning_rate = 0.00005\n",
        "  if epoch > 175:\n",
        "    learning_rate = 0.00003\n",
        "  if epoch > 200:\n",
        "    learning_rate = 0.00001\n",
        "\n",
        "  return learning_rate\n",
        "\n",
        "num_classes = 10\n",
        "num_rows = 32\n",
        "num_columns = 32\n",
        "weight_decay = 0.001\n",
        "batch_size = 512\n",
        "epochs = 225\n",
        "\n",
        "def main():\n",
        "  x_train, y_train = get_batches(data_batch_files = ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5'])\n",
        "  x_test, y_test = get_data(data_file = 'test_batch')\n",
        "\n",
        "  x_train, x_test = x_train / 255, x_test / 255\n",
        "  x_train, x_test = normalize_x_data(x_train, x_test)\n",
        "    \n",
        "  y_train, y_test = tf.keras.utils.to_categorical(y_train), tf.keras.utils.to_categorical(y_test)\n",
        "    \n",
        "  original_train_size = len(x_train)\n",
        "  new_train_size = len(x_train) - len(x_test)\n",
        "  x_val, y_val = x_train[new_train_size:original_train_size], y_train[new_train_size:original_train_size]\n",
        "  x_train, y_train = x_train[0:new_train_size], y_train[0:new_train_size]\n",
        "\n",
        "  #Preparing to fit the model with data augmentation\n",
        "  data_generator = ImageDataGenerator(rotation_range = 15, width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True) \n",
        "  train_generator = data_generator.flow(x_train, y_train, batch_size)\n",
        "  steps_per_epoch = len(x_train) // batch_size\n",
        "\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = tf.nn.relu, padding = 'same', kernel_regularizer = l2(weight_decay), input_shape = (num_rows, num_columns, 3)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = tf.nn.relu, padding = 'same', kernel_regularizer = l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = tf.nn.relu, padding = 'same', kernel_regularizer = l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = tf.nn.relu, padding = 'same', kernel_regularizer = l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = tf.nn.relu, padding = 'same', kernel_regularizer = l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = tf.nn.relu, padding = 'same', kernel_regularizer = l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation = tf.nn.relu, padding = 'same', kernel_regularizer = l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation = tf.nn.relu, padding = 'same', kernel_regularizer = l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation = tf.nn.relu, padding = 'same', kernel_regularizer = l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation = tf.nn.relu, padding = 'same', kernel_regularizer = l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "    \n",
        "  model.add(Dense(num_classes, activation = tf.nn.softmax))\n",
        "    \n",
        "  model.summary()\n",
        "    \n",
        "  optimizer = RMSprop(learning_rate = 0.001, decay = 1e-6)\n",
        "    \n",
        "  model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "  model.fit(train_generator, validation_data = (x_val, y_val), steps_per_epoch = steps_per_epoch, epochs = epochs, verbose = 1, callbacks = [LearningRateScheduler(learning_rate_schedule)])\n",
        "    \n",
        "  score = model.evaluate(x_test, y_test)\n",
        "  print('\\nTest loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "    \n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "a21a520b86c8565cbe0ea67594974457f8fd07b2b27abef0dbe31922aa522a8d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
